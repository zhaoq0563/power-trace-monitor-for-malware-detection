#!/usr/bin/env python
# python

import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats
from math import sqrt

def qmean(num):
	return sqrt(sum(n*n for n in num)/len(num))

def load_data(filename,size):
	s = []
	count = 1
	tmp = 0.0
	for line in open(filename,'r'):
		if count < size:
			tmp = tmp + (float(line.strip().split(',')[1]))
			count += 1
		else:
			count = 1
			s.append(tmp/size)
			tmp = float(line.strip().split(',')[1])
	return s

def mean_vector(s,windowsize,slide_speed):
	mean = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		mean.append(np.average(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return mean



def var_vector(s,windowsize,slide_speed):
	var = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		var.append(np.var(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return var

def skew_vector(s,windowsize,slide_speed):
	skew = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		skew.append(stats.skew(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return skew

def kurt_vector(s,windowsize,slide_speed):
	kurt = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		kurt.append(stats.kurtosis(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return kurt

def qmean_vector(s,windowsize,slide_speed):
	RMS = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		RMS.append(qmean(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return RMS

def winmax_vector(s,windowsize,slide_speed):
	winmax = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		winmax.append(max(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return winmax

def winmin_vector(s,windowsize,slide_speed):
	winmin = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		winmin.append(min(s[start:end+1]))
		start+=slide_speed
		end+=slide_speed
	return winmin

def iqr_vector(s,windowsize,slide_speed):
	IQR = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		IQR.append(np.subtract(*np.percentile(s[start:end+1], [75, 25])))
		start+=slide_speed
		end+=slide_speed
	return IQR

#print len(load_data("idle.txt",2))
#print (skew_vector(load_data("idle.txt",1),59375,500))
def gen_feature_matrix(s,windowsize,slide_speed):
	feature_matrix = []
	start = 0
	end = windowsize-1
	while end<(len(s)-1):
		window = []
		window.append(np.average(s[start:end+1]))
		window.append(np.var(s[start:end+1]))
		window.append(stats.skew(s[start:end+1]))
		window.append(stats.kurtosis(s[start:end+1]))
		window.append(qmean(s[start:end+1]))
		window.append(max(s[start:end+1]))
		window.append(min(s[start:end+1]))
		window.append(np.subtract(*np.percentile(s[start:end+1], [75, 25])))
		feature_matrix.append(window)
		start+=slide_speed
		end+=slide_speed
	return feature_matrix

def gen_training_matrix(infected,normal):
	training=[]
	for i in range(len(infected)):
		training.append(infected+normal)
	return training

def gen_labels(incected,normal):
	len_i = len(infected)
	len_n = len(normal)
	labels = []
	for i in range(len_i):
		labels.append(1)
	for j in range(len_n):
		labels.append(0)
	return labels

#loading data
s_i = load_data("raw/mabezat_idle_10min.txt",1)
s_n = load_data("raw/true_idle_10min_run2.txt",1)

s_t = load_data("raw/mabezat_new_10min.txt",1)

#define some parameters
windowsize = 198*15
slidespeed = 198

#generate feature vectors
infected = gen_feature_matrix(s_i,windowsize,slidespeed)
normal = gen_feature_matrix(s_n,windowsize,slidespeed)
test = gen_feature_matrix(s_t,windowsize,slidespeed)

#generating traning matrix and label vector
#training_matrix = infected+normal
#label_vector = gen_labels(infected,normal)


####################################################################
#								SVC					     		   #
####################################################################
#from sklearn import svm
#clf = svm.SVC(class_weight='auto')
#clf.fit(training_matrix, label_vector)
#print clf.predict(test)
#print len(clf.predict(test))
#print var_vector(s_i,windowsize,slidespeed)
#print var_vector(s_n,windowsize,slidespeed)
#print var_vector(s_t,windowsize,slidespeed)


####################################################################
#							    3-NN				     		   #
####################################################################
from sklearn.neighbors import KNeighborsClassifier
t_matrix = infected+normal
l_vector = gen_labels(infected,normal)
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(t_matrix, l_vector)
print sum(neigh.predict(test))
print len(neigh.predict(test))


####################################################################
#							   ExtraTree			     		   #
####################################################################
from sklearn import metrics
from sklearn.ensemble import ExtraTreesClassifier
# fit an Extra Trees model to the data
model1 = ExtraTreesClassifier()
model1.fit(t_matrix, l_vector)
print sum(model1.predict(test))
print len(model1.predict(test))
# display the relative importance of each attribute

####################################################################
#				     		Random Forest    	           		   #
####################################################################
training_matrix = np.asarray(infected+normal)
label_vector = np.asarray(gen_labels(infected,normal))

from milk.supervised import randomforest
from milk.supervised.multi import one_against_one
import milk.nfoldcrossvalidation
import milk.unsupervised
import pylab

# random forest learner
rf_learner = randomforest.rf_learner()
# rf is a binary learner, so we transform it into a multi-class classifier

model = rf_learner.train(training_matrix, label_vector) 
predictions = [model.apply(f) for f in test] 
print sum(predictions)
print len(predictions)
# cross validate with this learner and return predictions on left-out elements
#cmat,names, preds = milk.nfoldcrossvalidation(test, predictions, classifier=rf_learner, return_predictions=1)
#print 'cross-validation accuracy:', cmat.trace()/float(cmat.sum())
#x,v = milk.unsupervised.pca(training_matrix)
#colors = "rgb" # predicted colour
#marks = "xo" # whether the prediction was correct
#for (y,x),p,r in zip(x[:,:2], preds, label_vector):
#    c = colors[p]
#    m = marks[p == r]
#    pylab.plot(y,x,c+m)
#pylab.show()



